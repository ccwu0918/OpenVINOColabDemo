{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccwu0918/OpenVINOColabDemo/blob/main/405_paddle_ocr_webcam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Openvino Environment Test "
      ],
      "metadata": {
        "id": "Oc3NrvZFZO4E"
      },
      "id": "Oc3NrvZFZO4E"
    },
    {
      "cell_type": "code",
      "source": [
        "!cpuinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkwmRJEUZWRI",
        "outputId": "4d335486-8cb0-4a3b-84c4-9c383c9381fa"
      },
      "id": "lkwmRJEUZWRI",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: cpuinfo: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvNQpJRZjy0B",
        "outputId": "ddff47f0-b1c0-447f-8c68-f5d5365a3f66"
      },
      "id": "zvNQpJRZjy0B",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /etc/alternatives/cuda -al"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6E8ZVlKRIBT",
        "outputId": "8b6cc839-9e55-4217-8c37-fe35727efc24"
      },
      "id": "D6E8ZVlKRIBT",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lrwxrwxrwx 1 root root 20 Jun 29 13:36 /etc/alternatives/cuda -> /usr/local/cuda-11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85K8W2hyRU8T",
        "outputId": "412e23f3-d0ec-4e9c-b6af-42486c74129a"
      },
      "id": "85K8W2hyRU8T",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q0gRXoSRZAJ",
        "outputId": "cf3858d7-fa8b-401a-e55c-ec20531c1f89"
      },
      "id": "_Q0gRXoSRZAJ",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pip 21.1.3 from /usr/local/lib/python3.7/dist-packages/pip (python 3.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Colab with Paddleocr\n"
      ],
      "metadata": {
        "id": "g7KWv03bQ5aB"
      },
      "id": "g7KWv03bQ5aB"
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install \"paddleocr>=2.0.1\" # Recommend to use version 2.0.1+"
      ],
      "metadata": {
        "id": "ApxS_T8ozoff"
      },
      "id": "ApxS_T8ozoff",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content\n",
        "# !git clone https://github.com/PaddlePaddle/Paddle.git"
      ],
      "metadata": {
        "id": "YXCgh2Pi0Lk6"
      },
      "id": "YXCgh2Pi0Lk6",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Colab with OpenVINO\n"
      ],
      "metadata": {
        "id": "q9Wyjp1MN-FI"
      },
      "id": "q9Wyjp1MN-FI"
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install openvino==2022.1.0"
      ],
      "metadata": {
        "id": "mZLd-dj4O44p"
      },
      "id": "mZLd-dj4O44p",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install openvino-dev==2022.1.0\n",
        "# !pip install openvino-dev[caffe,kaldi,pytorch,mxnet,onnx,tensorflow2]==2022.1.0\n",
        "# !pip install openvino-dev[pytorch,tensorflow2]==2022.1.0\n",
        "# !pip install openvino-dev[tensorflow2]==2022.1.0"
      ],
      "metadata": {
        "id": "vM8WliqKOZA7"
      },
      "id": "vM8WliqKOZA7",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://registrationcenter-download.intel.com/akdlm/irc_nas/18617/l_openvino_toolkit_p_2022.1.0.643_offline.sh\n",
        "# !chmod +x l_openvino_toolkit_p_2022.1.0.643_offline.sh \n",
        "# !./l_openvino_toolkit_p_2022.1.0.643_offline.sh  -a -s --eula accept && rm ./l_openvino_toolkit_p_2022.1.0.643_offline.sh # --help\n",
        "# !ln /opt/intel/openvino_2022.1.0.643 /content/openvino_2022 -s"
      ],
      "metadata": {
        "id": "uAOs2XQZRxc9"
      },
      "id": "uAOs2XQZRxc9",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !sudo -E /opt/intel/openvino_2022/install_dependencies/install_openvino_dependencies.sh"
      ],
      "metadata": {
        "id": "ZNAwfp26Ry3B"
      },
      "id": "ZNAwfp26Ry3B",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install OpenVINO™ Notebooks\n"
      ],
      "metadata": {
        "id": "ds_Ulm4nS5ON"
      },
      "id": "ds_Ulm4nS5ON"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/openvinotoolkit/openvino_notebooks.git # --depth=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8PZFd8SS50W",
        "outputId": "b3cc0bb8-97d2-4472-c0c4-f36ad861d827"
      },
      "id": "H8PZFd8SS50W",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'openvino_notebooks'...\n",
            "remote: Enumerating objects: 2656, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 2656 (delta 19), reused 26 (delta 6), pack-reused 2599\u001b[K\n",
            "Receiving objects: 100% (2656/2656), 188.05 MiB | 25.42 MiB/s, done.\n",
            "Resolving deltas: 100% (1534/1534), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i 's/Pillow>=8.3.2/Pillow==9.0.0/g' ./openvino_notebooks/requirements.txt\n",
        "!sed -i 's/matplotlib<3.4/\\matplotlib==3.1.3/g' ./openvino_notebooks/requirements.txt"
      ],
      "metadata": {
        "id": "AhZVgLQjS2hT"
      },
      "id": "AhZVgLQjS2hT",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade -r ./openvino_notebooks/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiMOxNuhTPKX",
        "outputId": "229c88f3-5130-472e-8cda-5b34fee8e97f"
      },
      "id": "KiMOxNuhTPKX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Ignoring torch: markers 'sys_platform == \"darwin\"' don't match your environment\n",
            "Ignoring torchvision: markers 'sys_platform == \"darwin\"' don't match your environment\n",
            "Collecting openvino-dev[onnx,tensorflow2]==2022.1.0\n",
            "  Downloading openvino_dev-2022.1.0-7019-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (from -r ./openvino_notebooks/requirements.txt (line 2)) (4.4.0)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.5.1.tar.gz (14 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytube\n",
            "  Downloading pytube-12.1.0-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting yaspin\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Collecting fastseg\n",
            "  Downloading fastseg-0.1.2-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from -r ./openvino_notebooks/requirements.txt (line 8)) (7.7.0)\n",
            "Collecting ipywidgets\n",
            "  Downloading ipywidgets-7.7.1-py2.py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 61.3 MB/s \n",
            "\u001b[?25hCollecting torch<=1.7.1+cpu,>=1.5.1+cpu\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torch-1.7.1%2Bcpu-cp37-cp37m-linux_x86_64.whl (159.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 159.4 MB 28 kB/s \n",
            "\u001b[?25hCollecting torchvision<=0.8.2+cpu,>=0.6.1+cpu\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.8.2%2Bcpu-cp37-cp37m-linux_x86_64.whl (11.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8 MB 2.0 MB/s \n",
            "\u001b[?25hCollecting torchmetrics==0.6.2\n",
            "  Downloading torchmetrics-0.6.2-py3-none-any.whl (332 kB)\n",
            "\u001b[K     |████████████████████████████████| 332 kB 71.5 MB/s \n",
            "\u001b[?25hCollecting paddlepaddle==2.2.*\n",
            "  Downloading paddlepaddle-2.2.2-cp37-cp37m-manylinux1_x86_64.whl (108.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 108.4 MB 26 kB/s \n",
            "\u001b[?25hCollecting paddlehub\n",
            "  Downloading paddlehub-2.2.0-py3-none-any.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 62.5 MB/s \n",
            "\u001b[?25hCollecting paddle2onnx<=0.9.6,>=0.6\n",
            "  Downloading paddle2onnx-0.9.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7 MB 31.3 MB/s \n",
            "\u001b[?25hCollecting ppgan==2.1.*\n",
            "  Downloading ppgan-2.1.0-py3-none-any.whl (394 kB)\n",
            "\u001b[K     |████████████████████████████████| 394 kB 72.3 MB/s \n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 41.0 MB/s \n",
            "\u001b[?25hCollecting nncf[tf,torch]\n",
            "  Downloading nncf-2.3.0-py3-none-any.whl (770 kB)\n",
            "\u001b[K     |████████████████████████████████| 770 kB 23.2 MB/s \n",
            "\u001b[?25hCollecting tensorflow_datasets==4.2.0\n",
            "  Downloading tensorflow_datasets-4.2.0-py3-none-any.whl (3.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7 MB 43.5 MB/s \n",
            "\u001b[?25hCollecting monai\n",
            "  Downloading monai-0.9.0-202206131636-py3-none-any.whl (939 kB)\n",
            "\u001b[K     |████████████████████████████████| 939 kB 56.2 MB/s \n",
            "\u001b[?25hCollecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-1.6.4-py3-none-any.whl (585 kB)\n",
            "\u001b[K     |████████████████████████████████| 585 kB 59.2 MB/s \n",
            "\u001b[?25hCollecting jupyterlab\n",
            "  Downloading jupyterlab-3.4.3-py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 41.5 MB/s \n",
            "\u001b[?25hCollecting geffnet==0.9.8\n",
            "  Downloading geffnet-0.9.8-py3-none-any.whl (37 kB)\n",
            "Collecting matplotlib==3.1.3\n",
            "  Downloading matplotlib-3.1.3-cp37-cp37m-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.1 MB 20.2 MB/s \n",
            "\u001b[?25hCollecting jedi==0.17.2\n",
            "  Downloading jedi-0.17.2-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 41.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=56.0.0 in /usr/local/lib/python3.7/dist-packages (from -r ./openvino_notebooks/requirements.txt (line 45)) (57.4.0)\n",
            "Collecting setuptools>=56.0.0\n",
            "  Using cached setuptools-63.1.0-py3-none-any.whl (1.2 MB)\n",
            "Collecting Pillow==9.0.0\n",
            "  Downloading Pillow-9.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 24.4 MB/s \n",
            "\u001b[?25hCollecting ipykernel==5.*\n",
            "  Downloading ipykernel-5.5.6-py3-none-any.whl (121 kB)\n",
            "\u001b[K     |████████████████████████████████| 121 kB 58.3 MB/s \n",
            "\u001b[?25hCollecting ipython==7.16.3\n",
            "  Downloading ipython-7.16.3-py3-none-any.whl (783 kB)\n",
            "\u001b[K     |████████████████████████████████| 783 kB 43.6 MB/s \n",
            "\u001b[?25hCollecting pygments>=2.7.4\n",
            "  Downloading Pygments-2.12.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 47.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from -r ./openvino_notebooks/requirements.txt (line 50)) (3.7)\n",
            "Requirement already satisfied: rsa>=4.7 in /usr/local/lib/python3.7/dist-packages (from -r ./openvino_notebooks/requirements.txt (line 51)) (4.8)\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from -r ./openvino_notebooks/requirements.txt (line 52)) (1.0.2)\n",
            "Collecting paddlenlp==2.0.8\n",
            "  Downloading paddlenlp-2.0.8-py3-none-any.whl (571 kB)\n",
            "\u001b[K     |████████████████████████████████| 571 kB 48.4 MB/s \n",
            "\u001b[?25hCollecting nest-asyncio<=1.5.4\n",
            "  Downloading nest_asyncio-1.5.4-py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: jupyter-client<=7.2.0 in /usr/local/lib/python3.7/dist-packages (from -r ./openvino_notebooks/requirements.txt (line 55)) (5.3.5)\n",
            "Collecting jupyter-client<=7.2.0\n",
            "  Downloading jupyter_client-7.2.0-py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 59.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics==0.6.2->-r ./openvino_notebooks/requirements.txt (line 15)) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics==0.6.2->-r ./openvino_notebooks/requirements.txt (line 15)) (1.21.6)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from paddlepaddle==2.2.*->-r ./openvino_notebooks/requirements.txt (line 19)) (4.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from paddlepaddle==2.2.*->-r ./openvino_notebooks/requirements.txt (line 19)) (1.15.0)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from paddlepaddle==2.2.*->-r ./openvino_notebooks/requirements.txt (line 19)) (0.8.1)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle==2.2.*->-r ./openvino_notebooks/requirements.txt (line 19)) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from paddlepaddle==2.2.*->-r ./openvino_notebooks/requirements.txt (line 19)) (3.17.3)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.7/dist-packages (from ppgan==2.1.*->-r ./openvino_notebooks/requirements.txt (line 23)) (5.5.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from ppgan==2.1.*->-r ./openvino_notebooks/requirements.txt (line 23)) (1.4.1)\n",
            "Collecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting numba==0.53.1\n",
            "  Downloading numba-0.53.1-cp37-cp37m-manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 37.7 MB/s \n",
            "\u001b[?25hCollecting imageio==2.9.0\n",
            "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 14.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: librosa==0.8.1 in /usr/local/lib/python3.7/dist-packages (from ppgan==2.1.*->-r ./openvino_notebooks/requirements.txt (line 23)) (0.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from ppgan==2.1.*->-r ./openvino_notebooks/requirements.txt (line 23)) (4.64.0)\n",
            "Collecting imageio-ffmpeg\n",
            "  Downloading imageio_ffmpeg-0.4.7-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.9 MB 1.5 MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 73.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from ppgan==2.1.*->-r ./openvino_notebooks/requirements.txt (line 23)) (4.1.2.30)\n",
            "Requirement already satisfied: scikit-image>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from ppgan==2.1.*->-r ./openvino_notebooks/requirements.txt (line 23)) (0.18.3)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (from ppgan==2.1.*->-r ./openvino_notebooks/requirements.txt (line 23)) (1.9)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets==4.2.0->-r ./openvino_notebooks/requirements.txt (line 30)) (1.1.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets==4.2.0->-r ./openvino_notebooks/requirements.txt (line 30)) (1.1.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets==4.2.0->-r ./openvino_notebooks/requirements.txt (line 30)) (2.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets==4.2.0->-r ./openvino_notebooks/requirements.txt (line 30)) (0.3.5.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets==4.2.0->-r ./openvino_notebooks/requirements.txt (line 30)) (1.8.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets==4.2.0->-r ./openvino_notebooks/requirements.txt (line 30)) (4.1.1)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets==4.2.0->-r ./openvino_notebooks/requirements.txt (line 30)) (21.4.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets==4.2.0->-r ./openvino_notebooks/requirements.txt (line 30)) (5.7.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets==4.2.0->-r ./openvino_notebooks/requirements.txt (line 30)) (0.16.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3->-r ./openvino_notebooks/requirements.txt (line 43)) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3->-r ./openvino_notebooks/requirements.txt (line 43)) (1.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3->-r ./openvino_notebooks/requirements.txt (line 43)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3->-r ./openvino_notebooks/requirements.txt (line 43)) (0.11.0)\n",
            "Collecting parso<0.8.0,>=0.7.0\n",
            "  Downloading parso-0.7.1-py2.py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 77.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel==5.*->-r ./openvino_notebooks/requirements.txt (line 47)) (5.1.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from ipykernel==5.*->-r ./openvino_notebooks/requirements.txt (line 47)) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel==5.*->-r ./openvino_notebooks/requirements.txt (line 47)) (5.1.1)\n",
            "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "  Downloading prompt_toolkit-3.0.30-py3-none-any.whl (381 kB)\n",
            "\u001b[K     |████████████████████████████████| 381 kB 43.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython==7.16.3->-r ./openvino_notebooks/requirements.txt (line 48)) (0.2.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython==7.16.3->-r ./openvino_notebooks/requirements.txt (line 48)) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython==7.16.3->-r ./openvino_notebooks/requirements.txt (line 48)) (0.7.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from paddlenlp==2.0.8->-r ./openvino_notebooks/requirements.txt (line 53)) (3.1.0)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from paddlenlp==2.0.8->-r ./openvino_notebooks/requirements.txt (line 53)) (0.42.1)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from paddlenlp==2.0.8->-r ./openvino_notebooks/requirements.txt (line 53)) (0.70.13)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->ppgan==2.1.*->-r ./openvino_notebooks/requirements.txt (line 23)) (0.2.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->ppgan==2.1.*->-r ./openvino_notebooks/requirements.txt (line 23)) (1.6.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->ppgan==2.1.*->-r ./openvino_notebooks/requirements.txt (line 23)) (1.1.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->ppgan==2.1.*->-r ./openvino_notebooks/requirements.txt (line 23)) (2.1.9)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->ppgan==2.1.*->-r ./openvino_notebooks/requirements.txt (line 23)) (0.10.3.post1)\n",
            "Collecting llvmlite<0.37,>=0.36.0rc1\n",
            "  Downloading llvmlite-0.36.0-cp37-cp37m-manylinux2010_x86_64.whl (25.3 MB)\n",
            "\u001b[K     |███████████████████████▎        | 18.4 MB 5.6 MB/s eta 0:00:02"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Open Model Zoo"
      ],
      "metadata": {
        "id": "eAD_HqMdWQ7F"
      },
      "id": "eAD_HqMdWQ7F"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/openvinotoolkit/open_model_zoo.git\n",
        "%cd ./open_model_zoo\n",
        "!git submodule update --init --recursive\n",
        "%cd /content"
      ],
      "metadata": {
        "id": "4HSO5w1rWVO2"
      },
      "id": "4HSO5w1rWVO2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/ccwu0918/OpenVINOColabDemo/raw/main/omz_demos_build.zip\n",
        "!unzip -qq -o /content/omz_demos_build.zip -d /content/"
      ],
      "metadata": {
        "id": "Se7-DFHiZrdM"
      },
      "id": "Se7-DFHiZrdM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python -mpip install --user -r ./open_model_zoo/demos/requirements.txt"
      ],
      "metadata": {
        "id": "dDNF_0tvWbTo"
      },
      "id": "dDNF_0tvWbTo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install /content/open_model_zoo/demos/common/python"
      ],
      "metadata": {
        "id": "E4S3vT-TWfbv"
      },
      "id": "E4S3vT-TWfbv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Install OpenCV"
      ],
      "metadata": {
        "id": "mUBn4cCvS91k"
      },
      "id": "mUBn4cCvS91k"
    },
    {
      "cell_type": "code",
      "source": [
        "# !sudo -E /opt/intel/openvino_2022/extras/scripts/download_opencv.sh"
      ],
      "metadata": {
        "id": "cy_ZRSHgS89o"
      },
      "id": "cy_ZRSHgS89o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!source /opt/intel/openvino_2022/setupvars.sh"
      ],
      "metadata": {
        "id": "8AbjgBjuOkK6"
      },
      "id": "8AbjgBjuOkK6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ba0d9296-7fa6-4025-aedf-d2a19b05ff0d",
      "metadata": {
        "id": "ba0d9296-7fa6-4025-aedf-d2a19b05ff0d"
      },
      "source": [
        "# PaddleOCR with OpenVINO\n",
        "\n",
        "This demo shows how to run PPOCR model on OpenVINO natively. Instead of exporting the PaddlePaddle model to ONNX and then convert to the Intermediate Representation (IR) format through OpenVINO Model Optimizer, we can now read directly from the PaddlePaddle Model without any conversions. [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR) is an ultra-light OCR model trained with PaddlePaddle deep learning framework, that aims to create multilingual and practical OCR tools. \n",
        "\n",
        "The paddleOCR pre-trained model used in the demo refer to the \"Chinese and English ultra-lightweight PP-OCR model (9.4M)\". More open-sourced pre-trained models could be downloaded at [PaddleOCR Github](https://github.com/PaddlePaddle/PaddleOCR)  or [PaddleOCR Gitee](https://gitee.com/paddlepaddle/PaddleOCR). Working pipeline of the paddleOCR is as follows:\n",
        "\n",
        "<img align='center' src= \"https://raw.githubusercontent.com/yoyowz/classification/master/images/pipeline.png\" alt=\"drawing\" width=\"1000\"/>\n",
        "\n",
        "> Note: _To use this notebook with a webcam, you need to run the notebook on a computer with a webcam. If you run the notebook on a server, the webcam will not work. You can still do inference on a video._\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/openvino_notebooks/notebooks/405-paddle-ocr-webcam\n",
        "!sed -i 's/import paddle/\\# import paddle/g' ./pre_post_processing.py\n",
        "!sed -i 's/from paddle.nn/\\# from paddle.nn/g' ./pre_post_processing.py\n",
        "!sed -i 's/if isinstance(preds, paddle.Tensor)/\\# if isinstance(preds, paddle.Tensor)/g' ./pre_post_processing.py\n",
        "!sed -i 's/preds /\\# preds /g' ./pre_post_processing.py\n",
        "!sed -i 's/np.int)/np.int32)/g' ./pre_post_processing.py"
      ],
      "metadata": {
        "id": "NtEBjHLcK8rw"
      },
      "id": "NtEBjHLcK8rw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/openvino_notebooks/notebooks/405-paddle-ocr-webcam/pre_post_processing.py"
      ],
      "metadata": {
        "id": "wKnJCegnf0L5"
      },
      "id": "wKnJCegnf0L5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0e5a53f7-e1c5-4aca-879f-da2dd081b989",
      "metadata": {
        "tags": [],
        "id": "0e5a53f7-e1c5-4aca-879f-da2dd081b989"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "# import paddle\n",
        "import math\n",
        "import time\n",
        "import collections\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "from openvino.runtime import Core\n",
        "from IPython import display\n",
        "import copy\n",
        "\n",
        "### for Google Colab\n",
        "from google.colab.patches import cv2_imshow # Google Colab CV2\n",
        "import matplotlib.pyplot as plt\n",
        "# sys.path.append(\"../utils\") -->\n",
        "sys.path.append(\"/content/openvino_notebooks/notebooks/utils\")\n",
        "# sys.path.append(\"/content/openvino_notebooks/notebooks/405-paddle-ocr-webcam\")\n",
        "### for Google Colab\n",
        "import notebook_utils as utils\n",
        "import pre_post_processing as processing"
      ],
      "metadata": {
        "id": "mxVST0Ee90mn"
      },
      "id": "mxVST0Ee90mn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ee4ea41d-18a8-4914-b367-d5717111d8e8",
      "metadata": {
        "id": "ee4ea41d-18a8-4914-b367-d5717111d8e8"
      },
      "source": [
        "### Models for PaddleOCR\n",
        "\n",
        "PaddleOCR includes two parts of deep learning models, text detection and text recognition. Pre-trained models used in the demo are downloaded and stored in the \"model\" folder. Other pre-trained models for PaddleOCR could be download at [PaddleOCR Github](https://github.com/PaddlePaddle/PaddleOCR)  or [PaddleOCR Gitee](https://gitee.com/paddlepaddle/PaddleOCR).\n",
        "\n",
        "Only a few lines of code are required to run the model. First, we initialize the runtime for inference. Then we read the network architecture and model weights from the `.pdmodel` and `.pdiparams` files to load onto the CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "789f3c2f-d692-458e-8ec9-b7c6e63e3c49",
      "metadata": {
        "id": "789f3c2f-d692-458e-8ec9-b7c6e63e3c49"
      },
      "outputs": [],
      "source": [
        "# Define the function to download text detection and recognition models from PaddleOCR resources\n",
        "\n",
        "def run_model_download(model_url, model_file_path):\n",
        "    \"\"\"\n",
        "    Download pre-trained models from PaddleOCR resources\n",
        "\n",
        "    Parameters:\n",
        "        model_url: url link to pre-trained models\n",
        "        model_file_path: file path to store the downloaded model\n",
        "    \"\"\"\n",
        "    model_name = model_url.split(\"/\")[-1]\n",
        "    \n",
        "    if model_file_path.is_file(): \n",
        "        print(\"Model already exists\")\n",
        "    else:\n",
        "        # Download the model from the server, and untar it.\n",
        "        print(\"Downloading the pre-trained model... May take a while...\")\n",
        "\n",
        "        # create a directory\n",
        "        os.makedirs(\"model\", exist_ok=True)\n",
        "        urllib.request.urlretrieve(model_url, f\"model/{model_name} \")\n",
        "        print(\"Model Downloaded\")\n",
        "\n",
        "        file = tarfile.open(f\"model/{model_name} \")\n",
        "        res = file.extractall(\"model\")\n",
        "        file.close()\n",
        "        if not res:\n",
        "            print(f\"Model Extracted to {model_file_path}.\")\n",
        "        else:\n",
        "            print(\"Error Extracting the model. Please check the network.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e541150c-0f98-41c6-a97c-97acb26efd2f",
      "metadata": {
        "id": "e541150c-0f98-41c6-a97c-97acb26efd2f"
      },
      "source": [
        "#### Download the Model for Text **Detection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02fe27ea-0aaf-4ecb-bce2-858d70c84e93",
      "metadata": {
        "id": "02fe27ea-0aaf-4ecb-bce2-858d70c84e93"
      },
      "outputs": [],
      "source": [
        "# Directory where model will be downloaded\n",
        "\n",
        "det_model_url = \"https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_det_infer.tar\"\n",
        "det_model_file_path = Path(\"model/ch_ppocr_mobile_v2.0_det_infer/inference.pdmodel\")\n",
        "\n",
        "run_model_download(det_model_url, det_model_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f454531-81f0-4468-9867-3f9de9775aaf",
      "metadata": {
        "id": "2f454531-81f0-4468-9867-3f9de9775aaf"
      },
      "source": [
        "#### Load the Model for Text **Detection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9c5c83a-961c-4d98-8b20-5e96c8ef71f3",
      "metadata": {
        "id": "f9c5c83a-961c-4d98-8b20-5e96c8ef71f3"
      },
      "outputs": [],
      "source": [
        "# initialize inference engine for text detection\n",
        "core = Core()\n",
        "det_model = core.read_model(model=det_model_file_path)\n",
        "det_compiled_model = core.compile_model(model=det_model, device_name=\"CPU\")\n",
        "\n",
        "# get input and output nodes for text detection\n",
        "det_input_layer = det_compiled_model.input(0)\n",
        "det_output_layer = det_compiled_model.output(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ec5c940-626c-4cf7-a90f-833200969846",
      "metadata": {
        "id": "5ec5c940-626c-4cf7-a90f-833200969846"
      },
      "source": [
        "#### Download the Model for Text **Recognition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89c0a07a-8186-47b5-ad95-f104a84d13d8",
      "metadata": {
        "id": "89c0a07a-8186-47b5-ad95-f104a84d13d8"
      },
      "outputs": [],
      "source": [
        "rec_model_url = \"https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_rec_infer.tar\"\n",
        "rec_model_file_path = Path(\"model/ch_ppocr_mobile_v2.0_rec_infer/inference.pdmodel\")\n",
        "\n",
        "run_model_download(rec_model_url, rec_model_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20155aeb-401a-4759-baee-dcb24a605ece",
      "metadata": {
        "id": "20155aeb-401a-4759-baee-dcb24a605ece"
      },
      "source": [
        "#### Load the Model for Text **Recognition** with Dynamic Shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "927c2017-33af-4449-a7a4-10dfea86c110",
      "metadata": {
        "id": "927c2017-33af-4449-a7a4-10dfea86c110"
      },
      "source": [
        "Input to text recognition model refers to detected bounding boxes with different image sizes, i.e, dynamic input shapes. Hence:\n",
        "\n",
        "1. Input dimension with dynamic input shapes needs to be specified before loading text recognition model\n",
        "2. Dynamic shape is specified by assigning -1 to the input dimension or by setting the upper bound of the input dimension using, for example, Dimension(1, 512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d196913-6542-4177-87ab-c5aa1994f8e8",
      "metadata": {
        "id": "3d196913-6542-4177-87ab-c5aa1994f8e8"
      },
      "outputs": [],
      "source": [
        "# read the model and corresponding weights from file\n",
        "rec_model = core.read_model(model=rec_model_file_path)\n",
        "\n",
        "# assign dynamic shapes to every input layer on the last dimension\n",
        "for input_layer in rec_model.inputs:\n",
        "    input_shape = input_layer.partial_shape\n",
        "    input_shape[3] = -1\n",
        "    rec_model.reshape({input_layer: input_shape})\n",
        "\n",
        "rec_compiled_model = core.compile_model(model=rec_model, device_name=\"CPU\")\n",
        "\n",
        "# get input and output nodes\n",
        "rec_input_layer = rec_compiled_model.input(0)\n",
        "rec_output_layer = rec_compiled_model.output(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "573a1a11-faec-41af-bf43-08b90d28cec3",
      "metadata": {
        "id": "573a1a11-faec-41af-bf43-08b90d28cec3"
      },
      "source": [
        "### Preprocessing image functions for text detection and recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb3befa4-1cf8-4ac2-a5a0-e0e73498d755",
      "metadata": {
        "id": "fb3befa4-1cf8-4ac2-a5a0-e0e73498d755"
      },
      "source": [
        "Define preprosessing functions for text detection and recognition:\n",
        "1. Preprocessing for text detection: resize and normalize input images\n",
        "2. Preprocessing for text recognition: resize and normalize detected box images to the same size (e.g. size (3, 32, 320) for images with Chinese text) for easy batching in inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93bc8364-109b-4a32-b12b-bcb85f23b38c",
      "metadata": {
        "id": "93bc8364-109b-4a32-b12b-bcb85f23b38c"
      },
      "outputs": [],
      "source": [
        "# Preprocess for text detection\n",
        "def image_preprocess(input_image, size):\n",
        "    \"\"\"\n",
        "    Preprocess input image for text detection\n",
        "\n",
        "    Parameters:\n",
        "        input_image: input image \n",
        "        size: value for the image to be resized for text detection model\n",
        "    \"\"\"\n",
        "    img = cv2.resize(input_image, (size, size))\n",
        "    img = np.transpose(img, [2, 0, 1]) / 255\n",
        "    img = np.expand_dims(img, 0)\n",
        "    # NormalizeImage: {mean: [0.485, 0.456, 0.406], std: [0.229, 0.224, 0.225], is_scale: True}\n",
        "    img_mean = np.array([0.485, 0.456, 0.406]).reshape((3, 1, 1))\n",
        "    img_std = np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))\n",
        "    img -= img_mean\n",
        "    img /= img_std\n",
        "    return img.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9329d709-14bc-45aa-a1d7-d0d6d608933b",
      "metadata": {
        "id": "9329d709-14bc-45aa-a1d7-d0d6d608933b"
      },
      "outputs": [],
      "source": [
        "# Preprocess for text recognition\n",
        "def resize_norm_img(img, max_wh_ratio):\n",
        "    \"\"\"\n",
        "    Resize input image for text recognition\n",
        "\n",
        "    Parameters:\n",
        "        img: bounding box image from text detection \n",
        "        max_wh_ratio: value for the resizing for text recognition model\n",
        "    \"\"\"\n",
        "    rec_image_shape = [3, 32, 320]\n",
        "    imgC, imgH, imgW = rec_image_shape\n",
        "    assert imgC == img.shape[2]\n",
        "    character_type = \"ch\"\n",
        "    if character_type == \"ch\":\n",
        "        imgW = int((32 * max_wh_ratio))\n",
        "    h, w = img.shape[:2]\n",
        "    ratio = w / float(h)\n",
        "    if math.ceil(imgH * ratio) > imgW:\n",
        "        resized_w = imgW\n",
        "    else:\n",
        "        resized_w = int(math.ceil(imgH * ratio))\n",
        "    resized_image = cv2.resize(img, (resized_w, imgH))\n",
        "    resized_image = resized_image.astype('float32')\n",
        "    resized_image = resized_image.transpose((2, 0, 1)) / 255\n",
        "    resized_image -= 0.5\n",
        "    resized_image /= 0.5\n",
        "    padding_im = np.zeros((imgC, imgH, imgW), dtype=np.float32)\n",
        "    padding_im[:, :, 0:resized_w] = resized_image\n",
        "    return padding_im\n",
        "\n",
        "\n",
        "def prep_for_rec(dt_boxes, frame):\n",
        "    \"\"\"\n",
        "    Preprocessing of the detected bounding boxes for text recognition\n",
        "\n",
        "    Parameters:\n",
        "        dt_boxes: detected bounding boxes from text detection \n",
        "        frame: original input frame \n",
        "    \"\"\"\n",
        "    ori_im = frame.copy()\n",
        "    img_crop_list = [] \n",
        "    for bno in range(len(dt_boxes)):\n",
        "        tmp_box = copy.deepcopy(dt_boxes[bno])\n",
        "        img_crop = processing.get_rotate_crop_image(ori_im, tmp_box)\n",
        "        img_crop_list.append(img_crop)\n",
        "        \n",
        "    img_num = len(img_crop_list)\n",
        "    # Calculate the aspect ratio of all text bars\n",
        "    width_list = []\n",
        "    for img in img_crop_list:\n",
        "        width_list.append(img.shape[1] / float(img.shape[0]))\n",
        "    \n",
        "    # Sorting can speed up the recognition process\n",
        "    indices = np.argsort(np.array(width_list))\n",
        "    return img_crop_list, img_num, indices\n",
        "\n",
        "\n",
        "def batch_text_box(img_crop_list, img_num, indices, beg_img_no, batch_num):\n",
        "    \"\"\"\n",
        "    Batch for text recognition\n",
        "\n",
        "    Parameters:\n",
        "        img_crop_list: processed detected bounding box images \n",
        "        img_num: number of bounding boxes from text detection\n",
        "        indices: sorting for bounding boxes to speed up text recognition\n",
        "        beg_img_no: the beginning number of bounding boxes for each batch of text recognition inference\n",
        "        batch_num: number of images for each batch\n",
        "    \"\"\"\n",
        "    norm_img_batch = []\n",
        "    max_wh_ratio = 0\n",
        "    end_img_no = min(img_num, beg_img_no + batch_num)\n",
        "    for ino in range(beg_img_no, end_img_no):\n",
        "        h, w = img_crop_list[indices[ino]].shape[0:2]\n",
        "        wh_ratio = w * 1.0 / h\n",
        "        max_wh_ratio = max(max_wh_ratio, wh_ratio)\n",
        "    for ino in range(beg_img_no, end_img_no):\n",
        "        norm_img = resize_norm_img(img_crop_list[indices[ino]], max_wh_ratio)\n",
        "        norm_img = norm_img[np.newaxis, :]\n",
        "        norm_img_batch.append(norm_img)\n",
        "\n",
        "    norm_img_batch = np.concatenate(norm_img_batch)\n",
        "    norm_img_batch = norm_img_batch.copy()\n",
        "    return norm_img_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ee36029-eabd-4ffc-ab45-ac293b62f32b",
      "metadata": {
        "id": "5ee36029-eabd-4ffc-ab45-ac293b62f32b"
      },
      "source": [
        "### Postprocessing image for text detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "409df7bc-2236-47ef-8645-48e9e40d05f1",
      "metadata": {
        "id": "409df7bc-2236-47ef-8645-48e9e40d05f1"
      },
      "outputs": [],
      "source": [
        "def post_processing_detection(frame, det_results):\n",
        "    \"\"\"\n",
        "    Postprocess the results from text detection into bounding boxes\n",
        "\n",
        "    Parameters:\n",
        "        frame: input image \n",
        "        det_results: inference results from text detection model\n",
        "    \"\"\"   \n",
        "    ori_im = frame.copy()\n",
        "    data = {'image': frame}\n",
        "    data_resize = processing.DetResizeForTest(data)\n",
        "    data_list = []\n",
        "    keep_keys = ['image', 'shape']\n",
        "    for key in keep_keys:\n",
        "        data_list.append(data_resize[key])\n",
        "    img, shape_list = data_list\n",
        "\n",
        "    shape_list = np.expand_dims(shape_list, axis=0) \n",
        "    pred = det_results[0]    \n",
        "    # if isinstance(pred, paddle.Tensor):\n",
        "    #     pred = pred.numpy()\n",
        "    segmentation = pred > 0.3\n",
        "\n",
        "    boxes_batch = []\n",
        "    for batch_index in range(pred.shape[0]):\n",
        "        src_h, src_w, ratio_h, ratio_w = shape_list[batch_index]\n",
        "        mask = segmentation[batch_index]\n",
        "        boxes, scores = processing.boxes_from_bitmap(pred[batch_index], mask, src_w, src_h)\n",
        "        boxes_batch.append({'points': boxes})\n",
        "    post_result = boxes_batch\n",
        "    dt_boxes = post_result[0]['points']\n",
        "    dt_boxes = processing.filter_tag_det_res(dt_boxes, ori_im.shape)    \n",
        "    return dt_boxes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01d3695c-42c3-43d3-8472-9f16913182bf",
      "metadata": {
        "id": "01d3695c-42c3-43d3-8472-9f16913182bf"
      },
      "source": [
        "### Main processing function for PaddleOCR"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17ce8c76-3ea5-402c-b820-a403bf12cc05",
      "metadata": {
        "id": "17ce8c76-3ea5-402c-b820-a403bf12cc05"
      },
      "source": [
        "Run paddleOCR function in different operations, either a webcam or a video file. See the list of procedures below:\n",
        "\n",
        "1. Create a video player to play with target fps (`utils.VideoPlayer`).\n",
        "2. Prepare a set of frames for text detection and recognition.\n",
        "3. Run AI inference for both text detection and recognition.\n",
        "4. Visualize the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de5b68ee-bd25-4dd8-9e87-3fe6971c6e64",
      "metadata": {
        "id": "de5b68ee-bd25-4dd8-9e87-3fe6971c6e64"
      },
      "outputs": [],
      "source": [
        "def run_paddle_ocr(source=0, flip=False, use_popup=False, skip_first_frames=0):\n",
        "    \"\"\"\n",
        "    Main function to run the paddleOCR inference:\n",
        "    1. Create a video player to play with target fps (utils.VideoPlayer).\n",
        "    2. Prepare a set of frames for text detection and recognition.\n",
        "    3. Run AI inference for both text detection and recognition.\n",
        "    4. Visualize the results.\n",
        "\n",
        "    Parameters:\n",
        "        source: the webcam number to feed the video stream with primary webcam set to \"0\", or the video path.  \n",
        "        flip: to be used by VideoPlayer function for flipping capture image\n",
        "        use_popup: False for showing encoded frames over this notebook, True for creating a popup window.\n",
        "        skip_first_frames: Number of frames to skip at the beginning of the video. \n",
        "    \"\"\"\n",
        "    # create video player to play with target fps\n",
        "    player = None\n",
        "    try:\n",
        "        player = utils.VideoPlayer(source=source, flip=flip, fps=30, skip_first_frames=skip_first_frames)\n",
        "        # Start video capturing\n",
        "        player.start()\n",
        "        if use_popup:\n",
        "            title = \"Press ESC to Exit\"\n",
        "            cv2.namedWindow(winname=title, flags=cv2.WINDOW_GUI_NORMAL | cv2.WINDOW_AUTOSIZE)\n",
        "\n",
        "        processing_times = collections.deque()\n",
        "        while True:\n",
        "            # grab the frame\n",
        "            frame = player.next()\n",
        "            if frame is None:\n",
        "                print(\"Source ended\")\n",
        "                break\n",
        "            # if frame larger than full HD, reduce size to improve the performance\n",
        "            scale = 1280 / max(frame.shape)\n",
        "            if scale < 1:\n",
        "                frame = cv2.resize(src=frame, dsize=None, fx=scale, fy=scale,\n",
        "                                   interpolation=cv2.INTER_AREA)\n",
        "            # preprocess image for text detection\n",
        "            test_image = image_preprocess(frame, 640)\n",
        "                \n",
        "            # measure processing time for text detection\n",
        "            start_time = time.time()\n",
        "            # perform the inference step\n",
        "            det_results = det_compiled_model([test_image])[det_output_layer]\n",
        "            stop_time = time.time()\n",
        "\n",
        "            # Postprocessing for Paddle Detection\n",
        "            dt_boxes = post_processing_detection(frame, det_results)\n",
        "\n",
        "            processing_times.append(stop_time - start_time)\n",
        "            # use processing times from last 200 frames\n",
        "            if len(processing_times) > 200:\n",
        "                processing_times.popleft()\n",
        "            processing_time_det = np.mean(processing_times) * 1000\n",
        "\n",
        "            # Preprocess detection results for recognition\n",
        "            dt_boxes = processing.sorted_boxes(dt_boxes)  \n",
        "            batch_num = 6\n",
        "            img_crop_list, img_num, indices = prep_for_rec(dt_boxes, frame)\n",
        "            \n",
        "            # For storing recognition results, include two parts:\n",
        "            # txts are the recognized text results, scores are the recognition confidence level \n",
        "            rec_res = [['', 0.0]] * img_num\n",
        "            txts = [] \n",
        "            scores = []\n",
        "\n",
        "            for beg_img_no in range(0, img_num, batch_num):\n",
        "\n",
        "                # Recognition starts from here\n",
        "                norm_img_batch = batch_text_box(\n",
        "                    img_crop_list, img_num, indices, beg_img_no, batch_num)\n",
        "\n",
        "                # Run inference for text recognition \n",
        "                rec_results = rec_compiled_model([norm_img_batch])[rec_output_layer]\n",
        "\n",
        "                # Postprocessing recognition results\n",
        "                postprocess_op = processing.build_post_process(processing.postprocess_params)\n",
        "                rec_result = postprocess_op(rec_results)\n",
        "                for rno in range(len(rec_result)):\n",
        "                    rec_res[indices[beg_img_no + rno]] = rec_result[rno]   \n",
        "                if rec_res:\n",
        "                    txts = [rec_res[i][0] for i in range(len(rec_res))] \n",
        "                    scores = [rec_res[i][1] for i in range(len(rec_res))]                                                \n",
        "            image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "            boxes = dt_boxes\n",
        "            # draw text recognition results beside the image\n",
        "            draw_img = processing.draw_ocr_box_txt(\n",
        "                image,\n",
        "                boxes,\n",
        "                txts,\n",
        "                scores,\n",
        "                drop_score=0.5)\n",
        "\n",
        "            # Visualize PaddleOCR results\n",
        "            f_height, f_width = draw_img.shape[:2]\n",
        "            fps = 1000 / processing_time_det\n",
        "            cv2.putText(img=draw_img, text=f\"Inference time: {processing_time_det:.1f}ms ({fps:.1f} FPS)\", \n",
        "                        org=(20, 40),fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=f_width / 1000,\n",
        "                        color=(0, 0, 255), thickness=1, lineType=cv2.LINE_AA)\n",
        "            \n",
        "            # use this workaround if there is flickering\n",
        "            if use_popup: \n",
        "                draw_img = cv2.cvtColor(draw_img, cv2.COLOR_RGB2BGR)\n",
        "                cv2.imshow(winname=title, mat=draw_img)\n",
        "                key = cv2.waitKey(1)\n",
        "                # escape = 27\n",
        "                if key == 27:\n",
        "                    break\n",
        "            else:\n",
        "                # encode numpy array to jpg\n",
        "                draw_img = cv2.cvtColor(draw_img, cv2.COLOR_RGB2BGR)\n",
        "                _, encoded_img = cv2.imencode(ext=\".jpg\", img=draw_img,\n",
        "                                              params=[cv2.IMWRITE_JPEG_QUALITY, 100])\n",
        "                # create IPython image\n",
        "                i = display.Image(data=encoded_img)\n",
        "                # display the image in this notebook\n",
        "                # display.clear_output(wait=True)\n",
        "                display.display(i)\n",
        "\n",
        "                # print(str(ind)+\": /content/\"+str(ind)+\".jpg\")\n",
        "                # plt.imshow(frame)     \n",
        "                # plt.axis('off')           \n",
        "                # plt.show()                \n",
        "            \n",
        "    # ctrl-c\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Interrupted\")\n",
        "    # any different error\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "    finally:\n",
        "        if player is not None:\n",
        "            # stop capturing\n",
        "            player.stop()\n",
        "        if use_popup:\n",
        "            cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92f8855f-418a-4bda-8799-0953dda895c5",
      "metadata": {
        "id": "92f8855f-418a-4bda-8799-0953dda895c5"
      },
      "source": [
        "## Run Live PaddleOCR with OpenVINO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7642697d-d000-4a10-8e7b-2a519cf9e687",
      "metadata": {
        "id": "7642697d-d000-4a10-8e7b-2a519cf9e687"
      },
      "source": [
        "Run using a webcam as the video input. By default, the primary webcam is set with `source=0`. If you have multiple webcams, each one will be assigned a consecutive number starting at 0. Set `flip=True` when using a front-facing camera. Some web browsers, especially Mozilla Firefox, may cause flickering. If you experience flickering, set `use_popup=True`. *Note popup mode may not work if you run this notebook on a remote computer.*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install Pillow==9.0.0"
      ],
      "metadata": {
        "id": "zGTWafK79dmG"
      },
      "id": "zGTWafK79dmG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python -m pip uninstall matplotlib\n",
        "# !pip install matplotlib==3.1.3"
      ],
      "metadata": {
        "id": "ky0EA_3GDKVa"
      },
      "id": "ky0EA_3GDKVa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/openvino_notebooks/notebooks/405-paddle-ocr-webcam\n",
        "# import pre_post_processing as processing"
      ],
      "metadata": {
        "id": "Q_plaxe2EixX"
      },
      "id": "Q_plaxe2EixX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc274952-19aa-480d-ba50-a1146a89771b",
      "metadata": {
        "id": "dc274952-19aa-480d-ba50-a1146a89771b"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "run_paddle_ocr(source=0, flip=False, use_popup=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e9c2356-16e2-4ec9-a41e-ae7d03a25b5e",
      "metadata": {
        "id": "5e9c2356-16e2-4ec9-a41e-ae7d03a25b5e"
      },
      "source": [
        "If you don't have a webcam, you can still run this demo with a video file. Any [format supported by OpenCV](https://docs.opencv.org/4.5.1/dd/d43/tutorial_py_video_display.html) will work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6c9d077-70df-4a28-a372-7ee5168f6720",
      "metadata": {
        "id": "e6c9d077-70df-4a28-a372-7ee5168f6720"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "# Test OCR results on video file\n",
        "\n",
        "video_file = \"https://raw.githubusercontent.com/yoyowz/classification/master/images/test.mp4\"\n",
        "run_paddle_ocr(source=video_file, flip=False, use_popup=False, skip_first_frames=0)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "405-paddle-ocr-webcam.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}